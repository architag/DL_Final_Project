{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import TrajectoryDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting the Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data_points 15000\n",
      "Shape of state: torch.Size([1, 17, 2, 65, 65])\n",
      "Shape of action: torch.Size([1, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "dataset = TrajectoryDataset(\n",
    "    data_dir = \"../dataset/\",\n",
    "    states_filename = \"states.npy\",\n",
    "    actions_filename = \"actions.npy\",\n",
    "    s_transform = None,\n",
    "    a_transform = None,\n",
    ")\n",
    "\n",
    "# TODO: create two dataset for train and test\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "first_datapoint = next(iter(dataloader))\n",
    "state, action = first_datapoint\n",
    "\n",
    "print(f\"Number of data_points {len(dataloader)}\")\n",
    "print(f\"Shape of state: {state.shape}\")\n",
    "print(f\"Shape of action: {action.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "\n",
    "    def set_h(self, h):\n",
    "        self.h = h\n",
    "    \n",
    "    def reset_hc(self, h, c):\n",
    "        self.h = self.h.zero_() \n",
    "        self.c = self.c.zero_()\n",
    "    \"\"\"\n",
    "    Forward Method\n",
    "    Input: \n",
    "        action tensor (a) of shape: (B, input_size)\n",
    "    Output:   \n",
    "        predicted repr. tensor (s_yhat) of shape: (B, hidden_size)\n",
    "    \"\"\"\n",
    "    def forward(self, action):\n",
    "        self.h, self.c = self.lstm_cell(action, (self.h, self.c))\n",
    "        return self.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: assume no batch processing.\n",
    "def train(pred, enc, dataloader, criterion, optimizer, device):\n",
    "    # keeping encoder in eval mode\n",
    "    enc.eval()\n",
    "    for batch in dataloader:\n",
    "        a, s = batch\n",
    "        a, s = a.to(device), s.to(device)\n",
    "\n",
    "        ## initial observation\n",
    "        pred.set_h(enc(s[0]))\n",
    "\n",
    "        L = a.shape[0]\n",
    "        # TODO: check initialization\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(L):\n",
    "            action = a[i]\n",
    "            sy_hat = pred(action=action)\n",
    "            sy = enc(s[i+1])\n",
    "\n",
    "            loss += criterion(sy_hat, sy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ## clearing the hidden state and cell state\n",
    "        pred.reset_hc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 2048\n",
    "\n",
    "encoder = None\n",
    "predictor = Predictor(input_size=input_size, hidden_size=hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=0.001)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(predictor, encoder, dataloader, criterion, optimizer, device)\n",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(pred, enc, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(pred, enc, dataloader, criterion, optimizer, device):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# keeping encoder in eval mode\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     enc\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m         a, s \u001b[38;5;241m=\u001b[39m batch\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "train(predictor, encoder, dataloader, criterion, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
