{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import TrajectoryDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting the Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data_points 15000\n",
      "Shape of state: torch.Size([1, 17, 2, 65, 65])\n",
      "Shape of action: torch.Size([1, 16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/miniconda3/envs/ml/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "dataset = TrajectoryDataset(\n",
    "    data_dir = \"../dataset/\",\n",
    "    states_filename = \"states.npy\",\n",
    "    actions_filename = \"actions.npy\",\n",
    "    s_transform = None,\n",
    "    a_transform = None,\n",
    ")\n",
    "\n",
    "# TODO: create two dataset for train and test\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "first_datapoint = next(iter(dataloader))\n",
    "state, action = first_datapoint\n",
    "\n",
    "print(f\"Number of data_points {len(dataloader)}\")\n",
    "print(f\"Shape of state: {state.shape}\")\n",
    "print(f\"Shape of action: {action.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the Model\n",
    "\n",
    "1. `Encoder`: which will be a simple CNN network.\n",
    "2. `Predictor`: which will be a simple LSTM Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 12, padding=1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(12, 12, padding=1, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(12, 12, padding=1, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.bn3 = nn.BatchNorm2d(12)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d((6, 5), stride=2)\n",
    "        self.pool2 = nn.MaxPool2d((5, 5), stride=5)\n",
    "        # h -> (5, 5, stride=1) -> (3, 3)\n",
    "        # h = 65 -> 8748\n",
    "        self.fc1 = nn.Linear(432, 4096)\n",
    "        self.fc2 = nn.Linear(4096, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h,w = 65\n",
    "        x = self.conv1(x)        \n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x1 = x\n",
    "\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = x2 + x1\n",
    "        x2 = self.pool1(x2)\n",
    "        # h,w = 31 \n",
    "\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = x3 + x2\n",
    "        x3 = self.pool2(x3)\n",
    "        # h,w = 6\n",
    "\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        # (b,12*6*6)\n",
    "        x3 = self.fc1(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = self.fc2(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "\n",
    "    def set_hc(self, h, c):\n",
    "        self.h = h\n",
    "        self.c = c \n",
    "    \n",
    "    def reset_hc(self):\n",
    "        self.h = self.h.zero_() \n",
    "        self.c = self.c.zero_()\n",
    "    \"\"\"\n",
    "    Forward Method\n",
    "    Input: \n",
    "        action tensor (a) of shape: (B, input_size)\n",
    "    Output:   \n",
    "        predicted repr. tensor (s_yhat) of shape: (B, hidden_size)\n",
    "    \"\"\"\n",
    "    def forward(self, action):\n",
    "        self.h, self.c = self.lstm_cell(action, (self.h, self.c))\n",
    "        return self.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training \n",
    "We define `train_separate()` function, which does the training step when encoder is trained separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_separate(pred, enc, dataloader, criterion, optimizer, device):\n",
    "    # keeping encoder in eval mode\n",
    "    pred, enc = pred.to(device), enc.to(device)\n",
    "    enc.eval()\n",
    "\n",
    "    for batch in dataloader:\n",
    "        ## shape of [ s = (b, L+1, c, h, w)]  [a = (b, L, 2)]\n",
    "        s, a = batch\n",
    "        s, a = s.to(device), a.to(device)\n",
    "\n",
    "        ## initial observation\n",
    "        o = s[:, 0, :, :, :]\n",
    "        so = enc(o)\n",
    "        co = torch.zeros(so.shape).to(device)\n",
    "        pred.set_hc(so, co)\n",
    "        \n",
    "        loss ,L = 0, a.shape[1]\n",
    "        for i in range(L):\n",
    "            sy_hat = pred(a[:, i, :])\n",
    "            sy = enc(s[:, i+1, :, :, :])\n",
    "            loss += criterion(sy_hat, sy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "        ## clearing the hidden state and cell state\n",
    "        pred.reset_hc()\n",
    "        break     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 1024 \n",
    "\n",
    "encoder = SimpleEncoder(hidden_size) \n",
    "predictor = Predictor(input_size=input_size, hidden_size=hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=0.001)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_separate(predictor, encoder, dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Inference if the Encoder and Decoder is part of the model.\n",
    "If the encoder is trained together with JEPA, we define the forward inference and training step.  \n",
    "The pending step is the defining the loss function and how to do backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JEPAModel(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder(embed_size)\n",
    "        self.predictor = Predictor(2, 1024)\n",
    "        \n",
    "    def set_predictor(self, o, co):\n",
    "        so = self.encoder.forward(o)\n",
    "        self.predictor.set_hc(so, co)\n",
    "        return so\n",
    "    \n",
    "    def reset_predictor(self):\n",
    "        self.predictor.reset_hc()\n",
    "\n",
    "    def forward(self, action, state):\n",
    "        sy_hat = self.predictor(action)\n",
    "        sy = self.encoder(state)\n",
    "        return sy_hat, sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_inference(model, actions, states):\n",
    "    # shape of states = (b, L+1, c, h, w)\n",
    "    # shape of action = (b, L, 2)\n",
    "    B, L, D = state.shape[0], actions.shape[1], model.predictor.hidden_size\n",
    "\n",
    "    o = states[:, 0, :, :, :]\n",
    "    co = torch.zeros((B, D)).to(o.device)\n",
    "    model.set_predictor(o, co)\n",
    "\n",
    "    result = torch.empty((B, L, D))\n",
    "    for i in range(L):\n",
    "        sy_hat, _ = model(actions[:, i, :], states[:, i+1, :, :, :])\n",
    "        result[:, i, :] = sy_hat\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states shape: torch.Size([1, 17, 2, 65, 65])\n",
      "actions shape: torch.Size([1, 16, 2])\n",
      "torch.Size([1, 16, 1024])\n"
     ]
    }
   ],
   "source": [
    "model = JEPAModel(1024)\n",
    "\n",
    "# first_datapoint = next(iter(dataloader))\n",
    "states, actions = first_datapoint\n",
    "model = model.to(device)\n",
    "states = states.to(device)\n",
    "actions = actions.to(device)\n",
    "\n",
    "print(f\"states shape: {states.shape}\")\n",
    "print(f\"actions shape: {actions.shape}\")\n",
    "\n",
    "result = forward_inference(model, actions, states)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are doing training of encoder and predictor together, then we need to handle all the different losses, defined in the figure\n",
    "\n",
    "![loss diagram](../../assets/loss_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_train_step(model, actions, states, optimizer):\n",
    "    B, L, D = state.shape[0], actions.shape[1], model.predictor.hidden_size\n",
    "\n",
    "    loss, loss1, loss2, loss3 = 0, 0, 0, 0\n",
    "\n",
    "    o = states[:, 0, :, :, :]\n",
    "    co = torch.zeros((B, D)).to(o.device)\n",
    "    so = model.set_predictor(o, co)\n",
    "    ## TODO: compute loss1 using `so`\n",
    "\n",
    "    for i in range(L):\n",
    "        sy_hat, sy = model(actions[:, i, :], states[:, i+1, :, :, :])\n",
    "        ## TODO: compute loss2 per iteration using `sy_hat`, `sy`\n",
    "        ## TODO: compute loss3 per iteration using `sy`\n",
    "        ## note: if we are using latent variables: we have to compute lossz\n",
    "        \n",
    "    loss = loss1 + loss2 + loss3\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
